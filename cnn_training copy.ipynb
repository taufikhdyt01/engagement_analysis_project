{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "852583d1",
   "metadata": {},
   "source": [
    "### Setup Environment & Download FER2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4959174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup Environment & Download FER2013\n",
    "print(\"üöÄ CNN TRAINING - TAHAP 2 DIMULAI!\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Install dependencies\n",
    "%pip install tensorflow opencv-python pandas numpy matplotlib seaborn scikit-learn\n",
    "%pip install mtcnn pillow kaggle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import os\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"üîß TensorFlow version: {tf.__version__}\")\n",
    "print(f\"üñ•Ô∏è  GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"‚úÖ GPU detected! Training will be accelerated\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU detected. Training will use CPU (slower)\")\n",
    "\n",
    "# Set memory growth for GPU (if available)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"‚úÖ GPU memory growth enabled\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"‚ö†Ô∏è  GPU setup warning: {e}\")\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('data/fer2013', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('results/cnn', exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Environment setup complete!\")\n",
    "print(\"üìÅ Directories created: data/fer2013/, models/, results/cnn/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70755ec2",
   "metadata": {},
   "source": [
    "### Load and Preprocess FER2013 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869486c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load and Preprocess FER2013 Data\n",
    "print(\"üìä LOADING & PREPROCESSING FER2013 DATA...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Emotion labels (sesuai dengan Face API Anda)\n",
    "emotion_labels = ['angry', 'disgusted', 'fearful', 'happy', 'sad', 'surprised', 'neutral']\n",
    "num_classes = len(emotion_labels)\n",
    "\n",
    "print(f\"üéØ Target emotions: {emotion_labels}\")\n",
    "print(f\"üìä Number of classes: {num_classes}\")\n",
    "\n",
    "# Data generators untuk training\n",
    "def create_data_generators(batch_size=32, img_size=(48, 48)):\n",
    "    \"\"\"Create data generators for FER2013\"\"\"\n",
    "    \n",
    "    # Training data augmentation (seperti di paper)\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    # Validation data (no augmentation)\n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    # Load data\n",
    "    try:\n",
    "        # Split training data into train/validation (80/20)\n",
    "        train_datagen_split = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=10,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            shear_range=0.1,\n",
    "            zoom_range=0.1,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest',\n",
    "            validation_split=0.2  # Split 20% for validation\n",
    "        )\n",
    "        \n",
    "        # Training generator (80% of train data)\n",
    "        train_generator = train_datagen_split.flow_from_directory(\n",
    "            'data/fer2013/train',\n",
    "            target_size=img_size,\n",
    "            batch_size=batch_size,\n",
    "            color_mode='grayscale',\n",
    "            class_mode='categorical',\n",
    "            shuffle=True,\n",
    "            seed=42,\n",
    "            subset='training'  # Use training subset\n",
    "        )\n",
    "        \n",
    "        # Validation generator (20% of train data)\n",
    "        validation_generator = train_datagen_split.flow_from_directory(\n",
    "            'data/fer2013/train',  # Same directory as train\n",
    "            target_size=img_size,\n",
    "            batch_size=batch_size,\n",
    "            color_mode='grayscale',\n",
    "            class_mode='categorical',\n",
    "            shuffle=False,\n",
    "            seed=42,\n",
    "            subset='validation'  # Use validation subset\n",
    "        )\n",
    "        \n",
    "        test_generator = test_datagen.flow_from_directory(\n",
    "            'data/fer2013/test',\n",
    "            target_size=img_size,\n",
    "            batch_size=batch_size,\n",
    "            color_mode='grayscale',\n",
    "            class_mode='categorical',\n",
    "            shuffle=False,\n",
    "            seed=42\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Data generators created successfully!\")\n",
    "        \n",
    "        # Print dataset info\n",
    "        print(f\"\\nüìä Dataset Information:\")\n",
    "        print(f\"   Training samples: {train_generator.samples}\")\n",
    "        print(f\"   Validation samples: {validation_generator.samples}\")\n",
    "        print(f\"   Test samples: {test_generator.samples}\")\n",
    "        print(f\"   Batch size: {batch_size}\")\n",
    "        print(f\"   Image size: {img_size}\")\n",
    "        \n",
    "        # Print class distribution\n",
    "        print(f\"\\nüè∑Ô∏è  Class mapping:\")\n",
    "        for class_name, class_idx in train_generator.class_indices.items():\n",
    "            print(f\"   {class_idx}: {class_name}\")\n",
    "        \n",
    "        return train_generator, validation_generator, test_generator\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creating data generators: {e}\")\n",
    "        print(\"üí° Make sure FER2013 dataset is properly downloaded and structured\")\n",
    "        return None, None, None\n",
    "\n",
    "# Create data generators\n",
    "print(\"\\nüîÑ Creating data generators...\")\n",
    "train_gen, val_gen, test_gen = create_data_generators(batch_size=32, img_size=(48, 48))\n",
    "\n",
    "if train_gen is not None:\n",
    "    # Visualize sample data\n",
    "    print(\"\\nüñºÔ∏è  Visualizing sample training data...\")\n",
    "    \n",
    "    # Get a batch of training data\n",
    "    sample_batch_x, sample_batch_y = next(train_gen)\n",
    "    \n",
    "    # Plot sample images\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i in range(min(12, len(sample_batch_x))):\n",
    "        plt.subplot(3, 4, i+1)\n",
    "        plt.imshow(sample_batch_x[i].reshape(48, 48), cmap='gray')\n",
    "        \n",
    "        # Get emotion label\n",
    "        emotion_idx = np.argmax(sample_batch_y[i])\n",
    "        emotion_name = emotion_labels[emotion_idx] if emotion_idx < len(emotion_labels) else f\"Class_{emotion_idx}\"\n",
    "        \n",
    "        plt.title(f'{emotion_name}')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.suptitle('Sample Training Images from FER2013', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/cnn/fer2013_samples.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Sample visualization saved to results/cnn/fer2013_samples.png\")\n",
    "    \n",
    "    # Reset generator\n",
    "    train_gen.reset()\n",
    "    \n",
    "    print(\"\\nüéØ Data preprocessing complete!\")\n",
    "    print(\"üìà Ready for model building...\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Data preprocessing failed!\")\n",
    "    print(\"üîß Please check FER2013 dataset structure and try again\")\n",
    "\n",
    "print(\"\\nüéØ NEXT: Run Cell 3 to build CNN architecture\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f9eaf8",
   "metadata": {},
   "source": [
    "### Build CNN Architecture (Based on Paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bb9409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Build CNN Architecture (Based on Paper)\n",
    "print(\"üèóÔ∏è  BUILDING CNN ARCHITECTURE...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "def build_lightweight_cnn(input_shape=(48, 48, 1), num_classes=7):\n",
    "    \"\"\"\n",
    "    Build lightweight CNN for facial emotion recognition\n",
    "    Based on paper's approach with Adam robust optimization\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential([\n",
    "        # First Convolutional Block\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Second Convolutional Block  \n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Third Convolutional Block\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Flatten and Dense Layers\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        # Output layer\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build model\n",
    "print(\"üî® Building lightweight CNN model...\")\n",
    "model = build_lightweight_cnn(input_shape=(48, 48, 1), num_classes=7)\n",
    "\n",
    "# Compile with Adam optimizer (sesuai paper)\n",
    "print(\"‚öôÔ∏è  Compiling model with Adam optimizer...\")\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Model summary\n",
    "print(\"\\nüìã MODEL ARCHITECTURE SUMMARY:\")\n",
    "model.summary()\n",
    "\n",
    "# Calculate total parameters\n",
    "total_params = model.count_params()\n",
    "print(f\"\\nüìä Total Parameters: {total_params:,}\")\n",
    "print(f\"üèãÔ∏è  Model Size: ~{total_params * 4 / (1024*1024):.1f} MB (float32)\")\n",
    "\n",
    "# Visualize model architecture\n",
    "print(\"\\nüé® Creating model visualization...\")\n",
    "try:\n",
    "    tf.keras.utils.plot_model(\n",
    "        model, \n",
    "        to_file='results/cnn/model_architecture.png',\n",
    "        show_shapes=True,\n",
    "        show_layer_names=True,\n",
    "        rankdir='TB',\n",
    "        dpi=300\n",
    "    )\n",
    "    print(\"‚úÖ Model architecture saved to results/cnn/model_architecture.png\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Model visualization failed: {e}\")\n",
    "\n",
    "# Setup training callbacks\n",
    "print(\"\\nüîß Setting up training callbacks...\")\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Learning rate reduction\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.2,\n",
    "    patience=5,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Model checkpoint\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'models/best_fer_model.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping, reduce_lr, model_checkpoint]\n",
    "\n",
    "print(\"‚úÖ Callbacks configured:\")\n",
    "print(\"   - Early stopping (patience=10)\")\n",
    "print(\"   - Learning rate reduction (factor=0.2, patience=5)\")\n",
    "print(\"   - Model checkpoint (save best weights)\")\n",
    "\n",
    "# Training configuration\n",
    "EPOCHS = 100  # Paper menggunakan hingga 10,000 epochs, tapi kita batasi untuk speed\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print(f\"\\nüéØ TRAINING CONFIGURATION:\")\n",
    "print(f\"   Epochs: {EPOCHS}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Optimizer: Adam (lr=0.001)\")\n",
    "print(f\"   Loss: Categorical Crossentropy\")\n",
    "\n",
    "print(\"\\n‚úÖ Model architecture complete!\")\n",
    "print(\"üöÄ Ready for training...\")\n",
    "\n",
    "print(\"\\nüéØ NEXT: Run Cell 4 to start training the model\")\n",
    "\n",
    "# Save model configuration\n",
    "model_config = {\n",
    "    'architecture': 'Lightweight CNN',\n",
    "    'input_shape': [48, 48, 1],\n",
    "    'num_classes': 7,\n",
    "    'total_parameters': int(total_params),\n",
    "    'optimizer': 'Adam',\n",
    "    'learning_rate': 0.001,\n",
    "    'loss': 'categorical_crossentropy',\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'epochs': EPOCHS,\n",
    "    'emotion_labels': emotion_labels\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('models/model_config.json', 'w') as f:\n",
    "    json.dump(model_config, f, indent=2)\n",
    "\n",
    "print(\"üìÅ Model configuration saved to models/model_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f42dd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Execute Training\n",
    "print(\"üöÄ STARTING CNN TRAINING...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Training start time\n",
    "start_time = time.time()\n",
    "print(f\"‚è∞ Training started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Check if generators are available\n",
    "if 'train_gen' not in globals() or train_gen is None:\n",
    "    print(\"‚ùå Data generators not found! Please run Cell 2 first.\")\n",
    "else:\n",
    "    print(f\"üìä Training on {train_gen.samples} samples\")\n",
    "    print(f\"üìä Validating on {val_gen.samples} samples\")\n",
    "    \n",
    "    # Calculate steps per epoch\n",
    "    steps_per_epoch = train_gen.samples // BATCH_SIZE\n",
    "    validation_steps = val_gen.samples // BATCH_SIZE\n",
    "    \n",
    "    print(f\"üîÑ Steps per epoch: {steps_per_epoch}\")\n",
    "    print(f\"üîÑ Validation steps: {validation_steps}\")\n",
    "    \n",
    "    print(\"\\nüéØ Starting training process...\")\n",
    "    print(\"üìà Progress will be displayed below:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Train the model (Fixed for TensorFlow compatibility)\n",
    "        try:\n",
    "            # Try with workers parameter (TensorFlow 2.4+)\n",
    "            history = model.fit(\n",
    "                train_gen,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                epochs=EPOCHS,\n",
    "                validation_data=val_gen,\n",
    "                validation_steps=validation_steps,\n",
    "                callbacks=callbacks,\n",
    "                verbose=1,\n",
    "                workers=4,\n",
    "                use_multiprocessing=True\n",
    "            )\n",
    "        except TypeError:\n",
    "            # Fallback for older TensorFlow versions\n",
    "            print(\"‚ö†Ô∏è  Workers parameter not supported, using single-threaded training...\")\n",
    "            history = model.fit(\n",
    "                train_gen,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                epochs=EPOCHS,\n",
    "                validation_data=val_gen,\n",
    "                validation_steps=validation_steps,\n",
    "                callbacks=callbacks,\n",
    "                verbose=1\n",
    "            )\n",
    "        \n",
    "        # Training completed\n",
    "        end_time = time.time()\n",
    "        training_duration = end_time - start_time\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"üéâ TRAINING COMPLETED!\")\n",
    "        print(f\"‚è±Ô∏è  Total training time: {training_duration/3600:.2f} hours\")\n",
    "        print(f\"‚è∞ Completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        \n",
    "        # Get best metrics\n",
    "        best_epoch = np.argmax(history.history['val_accuracy'])\n",
    "        best_val_acc = max(history.history['val_accuracy'])\n",
    "        best_train_acc = history.history['accuracy'][best_epoch]\n",
    "        \n",
    "        print(f\"\\nüìä BEST RESULTS:\")\n",
    "        print(f\"   Best epoch: {best_epoch + 1}\")\n",
    "        print(f\"   Best validation accuracy: {best_val_acc:.4f}\")\n",
    "        print(f\"   Training accuracy at best epoch: {best_train_acc:.4f}\")\n",
    "        \n",
    "        # Save training history\n",
    "        history_df = pd.DataFrame(history.history)\n",
    "        history_df.to_csv('results/cnn/training_history.csv', index=False)\n",
    "        print(\"üíæ Training history saved to results/cnn/training_history.csv\")\n",
    "        \n",
    "        # Save final model\n",
    "        model.save('models/fer2013_trained_model.h5')\n",
    "        print(\"üíæ Final model saved to models/fer2013_trained_model.h5\")\n",
    "        \n",
    "        print(\"\\n‚úÖ Training artifacts saved successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Training failed with error: {e}\")\n",
    "        print(\"üîß Please check GPU memory and data generators\")\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚è∏Ô∏è  Training interrupted by user\")\n",
    "        print(\"üíæ Saving current model state...\")\n",
    "        model.save('models/fer2013_interrupted_model.h5')\n",
    "        print(\"‚úÖ Model saved as fer2013_interrupted_model.h5\")\n",
    "\n",
    "print(\"\\nüéØ NEXT: Run Cell 5 to visualize training results and evaluate model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39e2c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4B: Improved Training (OPTIONAL - jika mau improve accuracy)\n",
    "print(\"üîß IMPROVED CNN TRAINING...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Load best model dari training sebelumnya\n",
    "best_model = tf.keras.models.load_model('models/best_fer_model.h5')\n",
    "\n",
    "# Analysis: Cek apakah overfitting atau underfitting\n",
    "try:\n",
    "    history_df = pd.read_csv('results/cnn/training_history.csv')\n",
    "    \n",
    "    final_train_acc = history_df['accuracy'].iloc[-1]\n",
    "    final_val_acc = history_df['val_accuracy'].iloc[-1]\n",
    "    best_val_acc = history_df['val_accuracy'].max()\n",
    "    \n",
    "    print(f\"üìä TRAINING ANALYSIS:\")\n",
    "    print(f\"   Final train accuracy: {final_train_acc:.4f}\")\n",
    "    print(f\"   Final validation accuracy: {final_val_acc:.4f}\")\n",
    "    print(f\"   Best validation accuracy: {best_val_acc:.4f}\")\n",
    "    print(f\"   Gap (train-val): {final_train_acc - final_val_acc:.4f}\")\n",
    "    \n",
    "    if final_train_acc - final_val_acc > 0.1:\n",
    "        print(\"   üîç Analysis: OVERFITTING detected\")\n",
    "        improvement_strategy = \"reduce_overfitting\"\n",
    "    elif final_train_acc < 0.7:\n",
    "        print(\"   üîç Analysis: UNDERFITTING detected\") \n",
    "        improvement_strategy = \"increase_capacity\"\n",
    "    else:\n",
    "        print(\"   üîç Analysis: Model seems balanced\")\n",
    "        improvement_strategy = \"fine_tune\"\n",
    "        \n",
    "except:\n",
    "    print(\"‚ö†Ô∏è Could not load training history\")\n",
    "    improvement_strategy = \"fine_tune\"\n",
    "\n",
    "# Improvement strategies\n",
    "if improvement_strategy == \"reduce_overfitting\":\n",
    "    print(\"\\nüéØ STRATEGY: Reduce Overfitting\")\n",
    "    \n",
    "    # Add more regularization\n",
    "    improved_model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.4),  # Increased dropout\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.4),  # Increased dropout\n",
    "        \n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.5),  # More dropout\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),  # Reduced neurons\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.6),  # High dropout\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(7, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Lower learning rate\n",
    "    improved_model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0005),  # Lower LR\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "elif improvement_strategy == \"increase_capacity\":\n",
    "    print(\"\\nüéØ STRATEGY: Increase Model Capacity\")\n",
    "    \n",
    "    # Larger model\n",
    "    improved_model = Sequential([\n",
    "        Conv2D(64, (3, 3), activation='relu', input_shape=(48, 48, 1), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(1024, activation='relu'),  # Larger dense\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(7, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Higher learning rate\n",
    "    improved_model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(\"\\nüéØ STRATEGY: Continue with Current Model\")\n",
    "    print(\"‚úÖ Model performance is acceptable for fine-tuning\")\n",
    "    improved_model = best_model\n",
    "\n",
    "# Option to retrain\n",
    "retrain = input(\"\\n‚ùì Do you want to retrain with improved settings? (y/n): \").lower() == 'y'\n",
    "\n",
    "if retrain and improvement_strategy != \"fine_tune\":\n",
    "    print(f\"\\nüöÄ Starting improved training...\")\n",
    "    \n",
    "    # Enhanced callbacks\n",
    "    improved_callbacks = [\n",
    "        EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True, verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_accuracy', factor=0.3, patience=10, min_lr=1e-8, verbose=1),\n",
    "        ModelCheckpoint('models/improved_fer_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "    ]\n",
    "    \n",
    "    # Train improved model\n",
    "    improved_history = improved_model.fit(\n",
    "        train_gen,\n",
    "        steps_per_epoch=train_gen.samples // 32,\n",
    "        epochs=50,  # Fewer epochs but with better monitoring\n",
    "        validation_data=val_gen,\n",
    "        validation_steps=val_gen.samples // 32,\n",
    "        callbacks=improved_callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate improved model\n",
    "    improved_val_acc = max(improved_history.history['val_accuracy'])\n",
    "    print(f\"\\nüìä IMPROVED RESULTS:\")\n",
    "    print(f\"   Original validation accuracy: {best_val_acc:.4f}\")\n",
    "    print(f\"   Improved validation accuracy: {improved_val_acc:.4f}\")\n",
    "    print(f\"   Improvement: {improved_val_acc - best_val_acc:+.4f}\")\n",
    "    \n",
    "    if improved_val_acc > best_val_acc:\n",
    "        print(\"‚úÖ Improvement successful! Using improved model.\")\n",
    "        # Save as best model\n",
    "        improved_model.save('models/best_fer_model.h5')\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No significant improvement. Keeping original model.\")\n",
    "\n",
    "else:\n",
    "    print(\"‚úÖ Continuing with current model (63% accuracy)\")\n",
    "    print(\"üí° Fine-tuning will likely improve performance significantly\")\n",
    "\n",
    "print(f\"\\nüéØ RECOMMENDATION:\")\n",
    "print(f\"   üìà 63% accuracy is acceptable for base model\")\n",
    "print(f\"   üîß Fine-tuning with your data should reach 70%+ easily\")\n",
    "print(f\"   ‚≠ê Paper's final accuracy includes fine-tuning phase\")\n",
    "\n",
    "print(f\"\\nüéØ NEXT: Continue to Cell 5 for evaluation, then fine-tuning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9024902",
   "metadata": {},
   "source": [
    "### Model Evaluation & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c0c8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Model Evaluation & Visualization\n",
    "print(\"üìä MODEL EVALUATION & VISUALIZATION...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Load best model\n",
    "try:\n",
    "    best_model = tf.keras.models.load_model('models/best_fer_model.h5')\n",
    "    print(\"‚úÖ Best model loaded successfully!\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è  Best model not found, using current model\")\n",
    "    best_model = model\n",
    "\n",
    "# Plot training history\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training and validation metrics\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Accuracy plot\n",
    "    axes[0].plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "    axes[0].plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "    axes[0].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Accuracy')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss plot\n",
    "    axes[1].plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "    axes[1].plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "    axes[1].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/cnn/training_curves.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Plot training curves\n",
    "if 'history' in globals():\n",
    "    print(\"üìà Plotting training curves...\")\n",
    "    plot_training_history(history)\n",
    "    print(\"‚úÖ Training curves saved to results/cnn/training_curves.png\")\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\nüß™ Evaluating on test set...\")\n",
    "try:\n",
    "    test_loss, test_accuracy = best_model.evaluate(test_gen, verbose=1)\n",
    "    print(f\"\\nüìä TEST RESULTS:\")\n",
    "    print(f\"   Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"   Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "    \n",
    "    # Compare with paper results\n",
    "    paper_accuracy = 0.73  # 73% from paper\n",
    "    print(f\"\\nüìã COMPARISON WITH PAPER:\")\n",
    "    print(f\"   Paper accuracy: {paper_accuracy:.4f} ({paper_accuracy*100:.2f}%)\")\n",
    "    print(f\"   Our accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "    if test_accuracy >= paper_accuracy:\n",
    "        print(\"   üéâ We achieved better accuracy than the paper!\")\n",
    "    else:\n",
    "        print(\"   üìà Room for improvement, but good starting point\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Test evaluation failed: {e}\")\n",
    "\n",
    "# Generate predictions for confusion matrix\n",
    "print(\"\\nüîÑ Generating predictions for confusion matrix...\")\n",
    "try:\n",
    "    # Reset test generator\n",
    "    test_gen.reset()\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = best_model.predict(test_gen, verbose=1)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Get true labels\n",
    "    true_classes = test_gen.classes\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    \n",
    "    # Plot confusion matrix (style seperti paper)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Create heatmap\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=emotion_labels, yticklabels=emotion_labels,\n",
    "                cbar_kws={'label': 'Number of Samples'})\n",
    "    \n",
    "    plt.title('Confusion Matrix for Emotion Detection\\n(Similar to Paper Figure 12)', \n",
    "              fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Predicted Emotion Classes', fontsize=12)\n",
    "    plt.ylabel('Actual Emotion Classes', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/cnn/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Confusion matrix saved to results/cnn/confusion_matrix.png\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nüìã DETAILED CLASSIFICATION REPORT:\")\n",
    "    class_report = classification_report(true_classes, predicted_classes, \n",
    "                                       target_names=emotion_labels, \n",
    "                                       output_dict=True)\n",
    "    \n",
    "    # Format like paper's Table 2\n",
    "    print(f\"{'Class':<12} {'Precision (%)':<12} {'Recall (%)':<12} {'F1-score (%)':<12}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for i, emotion in enumerate(emotion_labels):\n",
    "        precision = class_report[emotion]['precision'] * 100\n",
    "        recall = class_report[emotion]['recall'] * 100\n",
    "        f1 = class_report[emotion]['f1-score'] * 100\n",
    "        print(f\"{emotion:<12} {precision:<12.0f} {recall:<12.0f} {f1:<12.0f}\")\n",
    "    \n",
    "    # Overall metrics\n",
    "    accuracy = class_report['accuracy'] * 100\n",
    "    weighted_avg = class_report['weighted avg']\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'Weighted avg':<12} {weighted_avg['precision']*100:<12.0f} {weighted_avg['recall']*100:<12.0f} {weighted_avg['f1-score']*100:<12.0f}\")\n",
    "    print(f\"Accuracy (%): {accuracy:.0f}\")\n",
    "    \n",
    "    # Save classification report\n",
    "    class_report_df = pd.DataFrame(class_report).transpose()\n",
    "    class_report_df.to_csv('results/cnn/classification_report.csv')\n",
    "    print(\"\\nüíæ Classification report saved to results/cnn/classification_report.csv\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Confusion matrix generation failed: {e}\")\n",
    "\n",
    "# Model performance summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìã CNN TRAINING SUMMARY REPORT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if 'history' in globals() and 'test_accuracy' in globals():\n",
    "    print(f\"üèóÔ∏è  Model Architecture: Lightweight CNN\")\n",
    "    print(f\"üìä Total Parameters: {model.count_params():,}\")\n",
    "    print(f\"‚è±Ô∏è  Training Time: {training_duration/3600:.2f} hours\")\n",
    "    print(f\"üéØ Best Validation Accuracy: {best_val_acc:.4f} ({best_val_acc*100:.2f}%)\")\n",
    "    print(f\"üß™ Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "    print(f\"üìã Paper Comparison: {'‚úÖ Better' if test_accuracy >= 0.73 else 'üìà Can improve'}\")\n",
    "\n",
    "print(f\"\\nüíæ SAVED ARTIFACTS:\")\n",
    "print(f\"   üìÅ models/best_fer_model.h5 - Best trained model\")\n",
    "print(f\"   üìÅ results/cnn/training_curves.png - Training visualization\")\n",
    "print(f\"   üìÅ results/cnn/confusion_matrix.png - Performance matrix\")\n",
    "print(f\"   üìÅ results/cnn/classification_report.csv - Detailed metrics\")\n",
    "\n",
    "print(f\"\\nüéâ CNN TRAINING PHASE COMPLETE!\")\n",
    "print(f\"üéØ NEXT PHASE: Fine-tuning with your video data\")\n",
    "\n",
    "print(\"\\nüéØ NEXT: Run Cell 6 to prepare for fine-tuning with your data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6913d9c5",
   "metadata": {},
   "source": [
    "### Model Evaluation & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1846cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Complete Face Extraction (ALL FUNCTIONS INCLUDED)\n",
    "print(\"üé• PREPARING YOUR VIDEO DATA FOR FINE-TUNING...\")\n",
    "print(\"Format: user{ID}_challenge{N}_time{HHMMSS}.jpg\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Install and import all required libraries\n",
    "try:\n",
    "    from mtcnn import MTCNN\n",
    "    print(\"‚úÖ MTCNN imported successfully\")\n",
    "except ImportError:\n",
    "    print(\"üì¶ Installing MTCNN...\")\n",
    "    %pip install mtcnn\n",
    "    from mtcnn import MTCNN\n",
    "    print(\"‚úÖ MTCNN installed and imported\")\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Initialize MTCNN detector globally\n",
    "detector = MTCNN()\n",
    "print(\"‚úÖ MTCNN detector initialized\")\n",
    "\n",
    "# ============================================================================\n",
    "# ALL REQUIRED FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def extract_face_from_frame(image_path, target_size=(48, 48)):\n",
    "    \"\"\"\n",
    "    Extract and preprocess face from video frame\n",
    "    Similar to paper's MTCNN approach\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read image\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            return None\n",
    "            \n",
    "        # Convert BGR to RGB\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Detect faces\n",
    "        results = detector.detect_faces(img_rgb)\n",
    "        \n",
    "        if len(results) > 0:\n",
    "            # Get the largest face (highest confidence)\n",
    "            best_face = max(results, key=lambda x: x['confidence'])\n",
    "            \n",
    "            if best_face['confidence'] > 0.7:  # Confidence threshold\n",
    "                # Extract face coordinates\n",
    "                x, y, w, h = best_face['box']\n",
    "                \n",
    "                # Add padding\n",
    "                padding = 20\n",
    "                x = max(0, x - padding)\n",
    "                y = max(0, y - padding)\n",
    "                w = min(img_rgb.shape[1] - x, w + 2*padding)\n",
    "                h = min(img_rgb.shape[0] - y, h + 2*padding)\n",
    "                \n",
    "                # Crop face\n",
    "                face = img_rgb[y:y+h, x:x+w]\n",
    "                \n",
    "                # Resize to target size\n",
    "                face_resized = cv2.resize(face, target_size)\n",
    "                \n",
    "                # Convert to grayscale (sesuai dengan training)\n",
    "                face_gray = cv2.cvtColor(face_resized, cv2.COLOR_RGB2GRAY)\n",
    "                \n",
    "                # Normalize\n",
    "                face_normalized = face_gray.astype('float32') / 255.0\n",
    "                \n",
    "                return face_normalized\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error processing {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def parse_your_filename(filename):\n",
    "    \"\"\"\n",
    "    Parse filename dengan format: user{ID}_challenge{N}_time{HHMMSS}.jpg\n",
    "    \"\"\"\n",
    "    \n",
    "    # Pattern untuk format Anda\n",
    "    pattern = r'user(\\d+)_challenge(\\d+)_time(\\d{6})\\.jpg'\n",
    "    match = re.match(pattern, filename)\n",
    "    \n",
    "    if match:\n",
    "        user_id = int(match.group(1))\n",
    "        challenge = int(match.group(2))\n",
    "        time_str = match.group(3)  # HHMMSS format\n",
    "        \n",
    "        # Convert HHMMSS to seconds for easier matching\n",
    "        hours = int(time_str[:2])\n",
    "        minutes = int(time_str[2:4])\n",
    "        seconds = int(time_str[4:6])\n",
    "        time_in_seconds = hours * 3600 + minutes * 60 + seconds\n",
    "        \n",
    "        return {\n",
    "            'user_id': user_id,\n",
    "            'challenge': challenge,\n",
    "            'time': time_str,\n",
    "            'time_seconds': time_in_seconds,\n",
    "            'formatted_time': f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
    "        }\n",
    "    \n",
    "    return None\n",
    "\n",
    "def map_frames_to_excel(video_directory, excel_data):\n",
    "    \"\"\"\n",
    "    Map video frames ke Excel data berdasarkan user_id, challenge, dan waktu\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üîç MAPPING VIDEO FRAMES TO EXCEL DATA...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Get all image files\n",
    "    image_files = []\n",
    "    for root, dirs, files in os.walk(video_directory):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                full_path = os.path.join(root, file)\n",
    "                parsed = parse_your_filename(file)\n",
    "                if parsed:\n",
    "                    parsed['filename'] = file\n",
    "                    parsed['filepath'] = full_path\n",
    "                    image_files.append(parsed)\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è Could not parse: {file}\")\n",
    "    \n",
    "    print(f\"üìÅ Found {len(image_files)} valid image files\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    frames_df = pd.DataFrame(image_files)\n",
    "    \n",
    "    if len(frames_df) == 0:\n",
    "        print(\"‚ùå No valid frames found!\")\n",
    "        return None\n",
    "    \n",
    "    # Display frame distribution\n",
    "    print(f\"\\nüìä FRAME DISTRIBUTION:\")\n",
    "    print(f\"   Users: {frames_df['user_id'].nunique()}\")\n",
    "    print(f\"   Challenges: {frames_df['challenge'].nunique()}\")\n",
    "    print(f\"   Total frames: {len(frames_df)}\")\n",
    "    \n",
    "    # Map challenge from page column\n",
    "    def extract_challenge_from_page(page):\n",
    "        \"\"\"Extract challenge number from page URL\"\"\"\n",
    "        if pd.isna(page):\n",
    "            return None\n",
    "        \n",
    "        page_str = str(page).lower()\n",
    "        if 'penjumlahan' in page_str or 'addition' in page_str:\n",
    "            return 1\n",
    "        elif 'perkalian' in page_str or 'multiplication' in page_str:\n",
    "            return 2\n",
    "        \n",
    "        return 1  # Default to challenge 1\n",
    "\n",
    "    excel_df = excel_data.copy()\n",
    "    excel_df['challenge'] = excel_df['page'].apply(extract_challenge_from_page)\n",
    "    \n",
    "    # Simple mapping strategy\n",
    "    mappings = []\n",
    "    \n",
    "    for _, frame_row in frames_df.iterrows():\n",
    "        # Find matching Excel records\n",
    "        matching_excel = excel_df[\n",
    "            (excel_df['user_id'] == frame_row['user_id']) &\n",
    "            (excel_df['challenge'] == frame_row['challenge'])\n",
    "        ]\n",
    "        \n",
    "        if len(matching_excel) > 0:\n",
    "            # Take first match for simplicity\n",
    "            excel_row = matching_excel.iloc[0]\n",
    "            mappings.append({\n",
    "                'filename': frame_row['filename'],\n",
    "                'filepath': frame_row['filepath'],\n",
    "                'user_id': frame_row['user_id'],\n",
    "                'challenge': frame_row['challenge'],\n",
    "                'frame_time': frame_row['formatted_time'],\n",
    "                'excel_idx': excel_row.name,\n",
    "                'engagement_score': excel_row['engagement_score'],\n",
    "                'engagement_level': excel_row['engagement_level'],\n",
    "                'face_api_emotions': [\n",
    "                    excel_row['neutral'], excel_row['happy'], excel_row['sad'],\n",
    "                    excel_row['angry'], excel_row['fearful'], \n",
    "                    excel_row['disgusted'], excel_row['surprised']\n",
    "                ]\n",
    "            })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    mapping_df = pd.DataFrame(mappings)\n",
    "    \n",
    "    print(f\"\\n‚úÖ MAPPING COMPLETE:\")\n",
    "    print(f\"   Total frames: {len(frames_df)}\")\n",
    "    print(f\"   Successfully mapped: {len(mapping_df)}\")\n",
    "    if len(frames_df) > 0:\n",
    "        print(f\"   Mapping rate: {len(mapping_df)/len(frames_df)*100:.1f}%\")\n",
    "    \n",
    "    return mapping_df\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "# Load your processed engagement data dari Tahap 1\n",
    "print(\"\\nüìä Loading your engagement data from Tahap 1...\")\n",
    "try:\n",
    "    your_data = pd.read_csv('results/processed_engagement_data.csv')\n",
    "    print(f\"‚úÖ Loaded {len(your_data)} records from {your_data['user_id'].nunique()} users\")\n",
    "    \n",
    "    # Display summary\n",
    "    print(f\"\\nüìã Your Data Summary:\")\n",
    "    print(f\"   Users: {your_data['user_id'].nunique()}\")\n",
    "    print(f\"   Records: {len(your_data)}\")\n",
    "    print(f\"   Unique pages: {your_data['page'].nunique()}\")\n",
    "    print(f\"   Engagement distribution:\")\n",
    "    for level, count in your_data['engagement_level'].value_counts().items():\n",
    "        print(f\"     {level}: {count}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading your data: {e}\")\n",
    "    print(\"üí° Make sure you completed Tahap 1 (baseline analysis)\")\n",
    "    # Create dummy data for testing\n",
    "    your_data = pd.DataFrame({\n",
    "        'user_id': [97, 97, 98, 98],\n",
    "        'page': ['/tantangan/penjumlahan', '/tantangan/perkalian', '/tantangan/penjumlahan', '/tantangan/perkalian'],\n",
    "        'engagement_score': [0.12, 0.08, 0.15, 0.11],\n",
    "        'engagement_level': ['Engaged', 'Disengaged', 'Highly Engaged', 'Engaged'],\n",
    "        'neutral': [0.7, 0.8, 0.6, 0.75],\n",
    "        'happy': [0.2, 0.1, 0.3, 0.15],\n",
    "        'sad': [0.05, 0.08, 0.04, 0.06],\n",
    "        'angry': [0.02, 0.01, 0.03, 0.02],\n",
    "        'fearful': [0.01, 0.005, 0.02, 0.01],\n",
    "        'disgusted': [0.01, 0.003, 0.01, 0.005],\n",
    "        'surprised': [0.01, 0.002, 0.005, 0.005]\n",
    "    })\n",
    "    print(\"‚ö†Ô∏è Using dummy data for testing\")\n",
    "\n",
    "# Setup directories\n",
    "video_frames_dir = \"data/video_frames\"  # SESUAIKAN dengan lokasi frame video Anda\n",
    "face_crops_dir = \"data/face_crops\"\n",
    "\n",
    "print(f\"\\nüéØ CONFIGURATION:\")\n",
    "print(f\"   Video frames directory: {video_frames_dir}\")\n",
    "print(f\"   Face crops output: {face_crops_dir}\")\n",
    "\n",
    "# Create face crops directory\n",
    "os.makedirs(face_crops_dir, exist_ok=True)\n",
    "\n",
    "# Map your frames to Excel data\n",
    "if os.path.exists(video_frames_dir):\n",
    "    print(f\"\\nüîç Mapping video frames to Excel data...\")\n",
    "    \n",
    "    # Use custom mapping function\n",
    "    frame_mapping = map_frames_to_excel(video_frames_dir, your_data)\n",
    "    \n",
    "    if frame_mapping is not None and len(frame_mapping) > 0:\n",
    "        print(f\"\\nüìä MAPPING RESULTS:\")\n",
    "        print(f\"   Successfully mapped: {len(frame_mapping)} frames\")\n",
    "        print(f\"   Users covered: {frame_mapping['user_id'].nunique()}\")\n",
    "        print(f\"   Challenges covered: {frame_mapping['challenge'].nunique()}\")\n",
    "        \n",
    "        # Save mapping results\n",
    "        frame_mapping.to_csv('data/frame_mapping.csv', index=False)\n",
    "        print(f\"üíæ Mapping saved to data/frame_mapping.csv\")\n",
    "        \n",
    "        # Extract faces from mapped frames\n",
    "        print(f\"\\nüéØ Extracting faces from video frames...\")\n",
    "        \n",
    "        face_data = []\n",
    "        processed_count = 0\n",
    "        \n",
    "        for idx, row in frame_mapping.iterrows():\n",
    "            if os.path.exists(row['filepath']):\n",
    "                # Extract face using MTCNN\n",
    "                face = extract_face_from_frame(row['filepath'])\n",
    "                \n",
    "                if face is not None:\n",
    "                    # Save processed face\n",
    "                    face_filename = f\"face_{processed_count:06d}_{row['user_id']}_c{row['challenge']}.jpg\"\n",
    "                    face_path = os.path.join(face_crops_dir, face_filename)\n",
    "                    \n",
    "                    # Save as image\n",
    "                    face_img = (face * 255).astype(np.uint8)\n",
    "                    cv2.imwrite(face_path, face_img)\n",
    "                    \n",
    "                    # Store metadata\n",
    "                    face_data.append({\n",
    "                        'face_path': face_path,\n",
    "                        'original_frame': row['filepath'],\n",
    "                        'user_id': row['user_id'],\n",
    "                        'challenge': row['challenge'],\n",
    "                        'frame_time': row['frame_time'],\n",
    "                        'engagement_score': row['engagement_score'],\n",
    "                        'engagement_level': row['engagement_level'],\n",
    "                        'face_api_emotions': row['face_api_emotions']\n",
    "                    })\n",
    "                    \n",
    "                    processed_count += 1\n",
    "                    \n",
    "                    if processed_count % 20 == 0:\n",
    "                        print(f\"   Processed {processed_count} faces...\")\n",
    "                else:\n",
    "                    print(f\"   ‚ö†Ô∏è No face detected in {row['filename']}\")\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        face_data_df = pd.DataFrame(face_data)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Face extraction complete!\")\n",
    "        print(f\"   Total faces extracted: {len(face_data_df)}\")\n",
    "        \n",
    "        if len(face_data_df) > 0:\n",
    "            print(f\"   Users: {face_data_df['user_id'].nunique()}\")\n",
    "            print(f\"   Challenges: {face_data_df['challenge'].nunique()}\")\n",
    "            \n",
    "            # Engagement distribution in extracted faces\n",
    "            print(f\"\\nüéØ Engagement distribution in extracted faces:\")\n",
    "            for level, count in face_data_df['engagement_level'].value_counts().items():\n",
    "                percentage = (count / len(face_data_df)) * 100\n",
    "                print(f\"   {level}: {count} ({percentage:.1f}%)\")\n",
    "            \n",
    "            # Save face data metadata\n",
    "            face_data_df.to_csv('data/face_data_metadata.csv', index=False)\n",
    "            print(f\"üíæ Face metadata saved to data/face_data_metadata.csv\")\n",
    "            \n",
    "            # Show sample mappings\n",
    "            print(f\"\\nüìã SAMPLE MAPPINGS:\")\n",
    "            sample_data = frame_mapping.head(3)[['filename', 'user_id', 'challenge', 'frame_time', 'engagement_level']]\n",
    "            print(sample_data.to_string(index=False))\n",
    "        else:\n",
    "            print(\"‚ùå No faces were successfully extracted\")\n",
    "            print(\"üí° Check if:\")\n",
    "            print(\"   - Images contain clear faces\")\n",
    "            print(\"   - Face detection confidence threshold (currently 0.7)\")\n",
    "            print(\"   - Image quality and lighting\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"‚ùå No frames could be mapped to Excel data\")\n",
    "        print(f\"üí° Check if:\")\n",
    "        print(f\"   - Filenames follow format: user{ID}_challenge{N}_time{HHMMSS}.jpg\")\n",
    "        print(f\"   - User IDs match those in Excel data\")\n",
    "        print(f\"   - Challenge mapping is correct\")\n",
    "        \n",
    "else:\n",
    "    print(f\"‚ùå Video frames directory not found: {video_frames_dir}\")\n",
    "    print(f\"üí° Please create the directory and add your video frames\")\n",
    "    \n",
    "    # Instructions for your specific format\n",
    "    print(f\"\\nüìã EXPECTED FILE FORMAT:\")\n",
    "    print(f\"   user97_challenge1_time115444.jpg\")\n",
    "    print(f\"   user97_challenge1_time115449.jpg\") \n",
    "    print(f\"   user97_challenge2_time120530.jpg\")\n",
    "    print(f\"   user98_challenge1_time091245.jpg\")\n",
    "    print(f\"   ...\")\n",
    "\n",
    "print(f\"\\nüéØ NEXT: Run Cell 7 to fine-tune the pre-trained model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398e377d",
   "metadata": {},
   "source": [
    "### Fine-tune Pre-trained Model with Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6347db88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Fine-tune Pre-trained Model (FIXED - Sequential Compatible)\n",
    "print(\"üîß FINE-TUNING PRE-TRAINED MODEL...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load pre-trained model\n",
    "print(\"üì¶ Loading pre-trained FER2013 model...\")\n",
    "try:\n",
    "    pretrained_model = tf.keras.models.load_model('models/best_fer_model.h5')\n",
    "    print(\"‚úÖ Pre-trained model loaded successfully!\")\n",
    "    print(f\"üìä Model type: {type(pretrained_model)}\")\n",
    "    \n",
    "    # Build the model to initialize input shape\n",
    "    if hasattr(pretrained_model, 'build') and not pretrained_model.built:\n",
    "        pretrained_model.build(input_shape=(None, 48, 48, 1))\n",
    "        print(\"‚úÖ Model built with input shape\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading pre-trained model: {e}\")\n",
    "    print(\"üí° Make sure you completed CNN training in previous steps\")\n",
    "\n",
    "# Load your face data\n",
    "try:\n",
    "    face_metadata = pd.read_csv('data/face_data_metadata.csv')\n",
    "    print(f\"‚úÖ Loaded face metadata: {len(face_metadata)} faces\")\n",
    "    print(f\"   Users: {face_metadata['user_id'].nunique()}\")\n",
    "    print(f\"   Challenges: {face_metadata['challenge'].nunique()}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading face metadata: {e}\")\n",
    "    print(\"üí° Make sure you completed face extraction in Cell 6\")\n",
    "    # Create dummy data for testing\n",
    "    face_metadata = pd.DataFrame({\n",
    "        'face_path': ['data/face_crops/face_000001_97_c1.jpg'],\n",
    "        'user_id': [97],\n",
    "        'engagement_score': [0.12],\n",
    "        'engagement_level': ['Engaged'],\n",
    "        'face_api_emotions': [[[0.7, 0.2, 0.05, 0.02, 0.01, 0.01, 0.01]]]\n",
    "    })\n",
    "    print(\"‚ö†Ô∏è Using dummy data for testing\")\n",
    "\n",
    "def create_fine_tuning_model_fixed(pretrained_model, num_classes=7):\n",
    "    \"\"\"\n",
    "    Create fine-tuning model from pre-trained CNN (Fixed for Sequential)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üî® Creating fine-tuning model...\")\n",
    "    \n",
    "    # Method 1: Clone and modify existing model\n",
    "    try:\n",
    "        # Get model config and weights\n",
    "        config = pretrained_model.get_config()\n",
    "        weights = pretrained_model.get_weights()\n",
    "        \n",
    "        # Create new model with same architecture\n",
    "        new_model = tf.keras.Sequential.from_config(config)\n",
    "        new_model.set_weights(weights)\n",
    "        \n",
    "        # Remove last few layers\n",
    "        while len(new_model.layers) > 0 and len(new_model.layers) >= 3:\n",
    "            new_model.pop()  # Remove last layer\n",
    "        \n",
    "        # Add new classification head for fine-tuning\n",
    "        new_model.add(Dense(128, activation='relu', name='fine_tune_dense1'))\n",
    "        new_model.add(Dropout(0.5, name='fine_tune_dropout1'))\n",
    "        new_model.add(Dense(64, activation='relu', name='fine_tune_dense2'))\n",
    "        new_model.add(Dropout(0.3, name='fine_tune_dropout2'))\n",
    "        new_model.add(Dense(num_classes, activation='softmax', name='fine_tune_output'))\n",
    "        \n",
    "        # Freeze early layers\n",
    "        for i, layer in enumerate(new_model.layers[:-4]):\n",
    "            layer.trainable = False\n",
    "            \n",
    "        print(f\"‚úÖ Fine-tuning model created using model cloning\")\n",
    "        return new_model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Model cloning failed: {e}\")\n",
    "        \n",
    "    # Method 2: Create new model and transfer weights layer by layer\n",
    "    try:\n",
    "        print(\"üîÑ Trying weight transfer method...\")\n",
    "        \n",
    "        # Create new model with similar architecture\n",
    "        new_model = Sequential([\n",
    "            Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            Dropout(0.25),\n",
    "            \n",
    "            Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            Dropout(0.25),\n",
    "            \n",
    "            Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            Dropout(0.25),\n",
    "            \n",
    "            Flatten(),\n",
    "            # Modified dense layers for fine-tuning\n",
    "            Dense(256, activation='relu'),  # Smaller than original\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.5),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        # Build the model\n",
    "        new_model.build(input_shape=(None, 48, 48, 1))\n",
    "        \n",
    "        # Transfer weights from pretrained model (compatible layers only)\n",
    "        pretrained_weights = pretrained_model.get_weights()\n",
    "        new_weights = new_model.get_weights()\n",
    "        \n",
    "        # Transfer as many weights as possible\n",
    "        min_layers = min(len(pretrained_weights), len(new_weights) - 4)  # Keep last 4 layers random\n",
    "        \n",
    "        for i in range(min_layers):\n",
    "            if pretrained_weights[i].shape == new_weights[i].shape:\n",
    "                new_weights[i] = pretrained_weights[i]\n",
    "        \n",
    "        new_model.set_weights(new_weights)\n",
    "        \n",
    "        # Freeze early layers\n",
    "        for layer in new_model.layers[:-4]:\n",
    "            layer.trainable = False\n",
    "            \n",
    "        print(f\"‚úÖ Fine-tuning model created using weight transfer\")\n",
    "        return new_model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Weight transfer failed: {e}\")\n",
    "    \n",
    "    # Method 3: Use pretrained model as-is with modified training\n",
    "    print(\"üîÑ Using pretrained model as-is for fine-tuning...\")\n",
    "    \n",
    "    # Freeze early layers of pretrained model\n",
    "    for i, layer in enumerate(pretrained_model.layers[:-3]):\n",
    "        layer.trainable = False\n",
    "    \n",
    "    return pretrained_model\n",
    "\n",
    "# Create fine-tuning model\n",
    "print(\"\\nüèóÔ∏è Creating fine-tuning model...\")\n",
    "fine_tune_model = create_fine_tuning_model_fixed(pretrained_model)\n",
    "\n",
    "# Compile with lower learning rate for fine-tuning\n",
    "fine_tune_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),  # Lower LR for fine-tuning\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Fine-tuning model created and compiled!\")\n",
    "print(f\"üìä Trainable parameters: {sum([tf.keras.backend.count_params(w) for w in fine_tune_model.trainable_weights]):,}\")\n",
    "print(f\"üìä Total parameters: {fine_tune_model.count_params():,}\")\n",
    "\n",
    "# Prepare data generators for your data\n",
    "def create_your_data_generators_simple(face_metadata, face_crops_dir, batch_size=16):\n",
    "    \"\"\"\n",
    "    Create data generators from your extracted faces (SIMPLIFIED)\n",
    "    Using Face API emotions as pseudo-labels\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üìä Preparing your face data...\")\n",
    "    \n",
    "    # Prepare data arrays\n",
    "    face_paths = []\n",
    "    emotion_labels = []\n",
    "    engagement_labels = []\n",
    "    \n",
    "    for idx, row in face_metadata.iterrows():\n",
    "        if os.path.exists(row['face_path']):\n",
    "            face_paths.append(row['face_path'])\n",
    "            \n",
    "            # Use Face API emotions as labels\n",
    "            try:\n",
    "                if isinstance(row['face_api_emotions'], str):\n",
    "                    emotions = eval(row['face_api_emotions'])\n",
    "                else:\n",
    "                    emotions = row['face_api_emotions']\n",
    "                \n",
    "                # Ensure it's a list/array\n",
    "                if isinstance(emotions, (list, np.ndarray)) and len(emotions) >= 7:\n",
    "                    emotion_labels.append(emotions[:7])  # Take first 7 emotions\n",
    "                else:\n",
    "                    # Default neutral emotion\n",
    "                    emotion_labels.append([1, 0, 0, 0, 0, 0, 0])\n",
    "                    \n",
    "            except:\n",
    "                # Default neutral emotion if parsing fails\n",
    "                emotion_labels.append([1, 0, 0, 0, 0, 0, 0])\n",
    "                \n",
    "            engagement_labels.append(row['engagement_level'])\n",
    "    \n",
    "    print(f\"üìä Prepared {len(face_paths)} faces for training\")\n",
    "    \n",
    "    if len(face_paths) == 0:\n",
    "        print(\"‚ùå No valid face data found!\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    X = np.zeros((len(face_paths), 48, 48, 1))\n",
    "    y = np.array(emotion_labels)\n",
    "    \n",
    "    # Load and preprocess images\n",
    "    valid_indices = []\n",
    "    for i, face_path in enumerate(face_paths):\n",
    "        try:\n",
    "            img = cv2.imread(face_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (48, 48))\n",
    "                X[i] = img.reshape(48, 48, 1) / 255.0\n",
    "                valid_indices.append(i)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error loading {face_path}: {e}\")\n",
    "    \n",
    "    # Keep only valid data\n",
    "    if len(valid_indices) == 0:\n",
    "        print(\"‚ùå No valid images could be loaded!\")\n",
    "        return None, None, None, None\n",
    "        \n",
    "    X = X[valid_indices]\n",
    "    y = y[valid_indices]\n",
    "    \n",
    "    print(f\"‚úÖ Data arrays created: X{X.shape}, y{y.shape}\")\n",
    "    \n",
    "    # Split data (80% train, 20% validation)\n",
    "    if len(X) >= 5:  # Need minimum data for split\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "    else:\n",
    "        # Too little data, use all for training\n",
    "        X_train, X_val = X, X\n",
    "        y_train, y_val = y, y\n",
    "        print(\"‚ö†Ô∏è Limited data: using same data for train and validation\")\n",
    "    \n",
    "    print(f\"üìä Train: {X_train.shape[0]} samples\")\n",
    "    print(f\"üìä Validation: {X_val.shape[0]} samples\")\n",
    "    \n",
    "    return X_train, X_val, y_train, y_val\n",
    "\n",
    "# Create your data generators\n",
    "if len(face_metadata) > 0:\n",
    "    print(\"\\nüìä Creating data generators from your faces...\")\n",
    "    X_train, X_val, y_train, y_val = create_your_data_generators_simple(\n",
    "        face_metadata, face_crops_dir, batch_size=16\n",
    "    )\n",
    "    \n",
    "    if X_train is not None:\n",
    "        # Data augmentation for your data\n",
    "        your_datagen = ImageDataGenerator(\n",
    "            rotation_range=15,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            shear_range=0.1,\n",
    "            zoom_range=0.1,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest'\n",
    "        )\n",
    "        \n",
    "        # Setup callbacks for fine-tuning\n",
    "        fine_tune_callbacks = [\n",
    "            EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=8, min_lr=1e-8),\n",
    "            ModelCheckpoint('models/fine_tuned_model.h5', monitor='val_accuracy', \n",
    "                           save_best_only=True, verbose=1)\n",
    "        ]\n",
    "        \n",
    "        # Fine-tuning training\n",
    "        print(\"\\nüöÄ Starting fine-tuning...\")\n",
    "        print(\"‚öôÔ∏è Using lower learning rate and smaller batch size\")\n",
    "        print(\"üéØ Training on your programming context data...\")\n",
    "        \n",
    "        try:\n",
    "            fine_tune_history = fine_tune_model.fit(\n",
    "                your_datagen.flow(X_train, y_train, batch_size=8),  # Smaller batch size\n",
    "                steps_per_epoch=max(1, len(X_train) // 8),\n",
    "                epochs=30,  # Fewer epochs for fine-tuning\n",
    "                validation_data=(X_val, y_val),\n",
    "                callbacks=fine_tune_callbacks,\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            print(\"\\nüéâ Fine-tuning completed!\")\n",
    "            \n",
    "            # Evaluate fine-tuned model\n",
    "            print(\"\\nüìä Evaluating fine-tuned model...\")\n",
    "            val_loss, val_accuracy = fine_tune_model.evaluate(X_val, y_val, verbose=0)\n",
    "            print(f\"   Validation accuracy: {val_accuracy:.4f} ({val_accuracy*100:.2f}%)\")\n",
    "            \n",
    "            # Save fine-tuning results\n",
    "            fine_tune_history_df = pd.DataFrame(fine_tune_history.history)\n",
    "            fine_tune_history_df.to_csv('results/fine_tune_history.csv', index=False)\n",
    "            \n",
    "            print(\"üíæ Fine-tuning history saved to results/fine_tune_history.csv\")\n",
    "            \n",
    "            # Quick visualization\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            \n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.plot(fine_tune_history.history['accuracy'], label='Training')\n",
    "            plt.plot(fine_tune_history.history['val_accuracy'], label='Validation')\n",
    "            plt.title('Fine-tuning Accuracy')\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(fine_tune_history.history['loss'], label='Training')\n",
    "            plt.plot(fine_tune_history.history['val_loss'], label='Validation')\n",
    "            plt.title('Fine-tuning Loss')\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig('results/fine_tune_curves.png', dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            print(\"‚úÖ Fine-tuning visualization saved to results/fine_tune_curves.png\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Fine-tuning failed: {e}\")\n",
    "            print(\"üí° This might be due to limited data or model compatibility\")\n",
    "            print(\"   Consider using the pre-trained model as-is\")\n",
    "            \n",
    "    else:\n",
    "        print(\"‚ùå Could not prepare training data\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå No face data available for fine-tuning\")\n",
    "    print(\"üí° Please complete face extraction in Cell 6 first\")\n",
    "\n",
    "print(\"\\nüéØ NEXT: Run Cell 8 for hybrid analysis (Face API + Fine-tuned CNN)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff36118",
   "metadata": {},
   "source": [
    "### Hybrid Analysis - Face API + Fine-tuned CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0da352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Hybrid Analysis - Face API + CNN (FIXED - Complete)\n",
    "print(\"üîÑ HYBRID ANALYSIS: Face API + Fine-tuned CNN...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load models and data with error handling\n",
    "print(\"üì¶ Loading models and data...\")\n",
    "\n",
    "# Load baseline data (from Tahap 1)\n",
    "try:\n",
    "    baseline_data = pd.read_csv('results/processed_engagement_data.csv')\n",
    "    print(f\"‚úÖ Baseline data loaded: {len(baseline_data)} records\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading baseline data: {e}\")\n",
    "    print(\"üí° Using dummy baseline data for testing\")\n",
    "    baseline_data = pd.DataFrame({\n",
    "        'user_id': [97, 97, 98, 98, 99, 99],\n",
    "        'page': ['/tantangan/penjumlahan'] * 6,\n",
    "        'engagement_score': [0.12, 0.08, 0.15, 0.11, 0.09, 0.16],\n",
    "        'engagement_level': ['Engaged', 'Disengaged', 'Highly Engaged', 'Engaged', 'Disengaged', 'Highly Engaged'],\n",
    "        'neutral': [0.7, 0.8, 0.6, 0.75, 0.65, 0.55],\n",
    "        'happy': [0.2, 0.1, 0.3, 0.15, 0.25, 0.35],\n",
    "        'sad': [0.05, 0.08, 0.04, 0.06, 0.07, 0.03],\n",
    "        'angry': [0.02, 0.01, 0.03, 0.02, 0.01, 0.04],\n",
    "        'fearful': [0.01, 0.005, 0.02, 0.01, 0.015, 0.025],\n",
    "        'disgusted': [0.01, 0.003, 0.01, 0.005, 0.008, 0.015],\n",
    "        'surprised': [0.01, 0.002, 0.005, 0.005, 0.007, 0.02]\n",
    "    })\n",
    "\n",
    "# Load models with fallbacks\n",
    "original_model = None\n",
    "fine_tuned_model = None\n",
    "\n",
    "# Try to load fine-tuned model\n",
    "try:\n",
    "    fine_tuned_model = tf.keras.models.load_model('models/fine_tuned_model.h5')\n",
    "    print(\"‚úÖ Fine-tuned model loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Fine-tuned model not found: {e}\")\n",
    "    \n",
    "    # Try to load original pre-trained model as fallback\n",
    "    try:\n",
    "        fine_tuned_model = tf.keras.models.load_model('models/best_fer_model.h5')\n",
    "        print(\"‚úÖ Using pre-trained model as fallback\")\n",
    "    except Exception as e2:\n",
    "        print(f\"‚ùå No models available: {e2}\")\n",
    "        fine_tuned_model = None\n",
    "\n",
    "# Load face metadata\n",
    "face_metadata = None\n",
    "try:\n",
    "    if os.path.exists('data/face_data_metadata.csv'):\n",
    "        face_metadata = pd.read_csv('data/face_data_metadata.csv')\n",
    "        print(f\"‚úÖ Face metadata loaded: {len(face_metadata)} faces\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Face metadata not found\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error loading face metadata: {e}\")\n",
    "\n",
    "class HybridEngagementAnalyzer:\n",
    "    \"\"\"\n",
    "    Hybrid system combining Face API and CNN predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, face_api_weight=0.7, cnn_weight=0.3):\n",
    "        self.face_api_weight = face_api_weight\n",
    "        self.cnn_weight = cnn_weight\n",
    "        self.emotion_weights = {\n",
    "            'angry': -0.10, 'disgusted': -0.05, 'fearful': -0.20,\n",
    "            'sad': -0.05, 'happy': 0.10, 'surprised': 0.15, 'neutral': 0.30\n",
    "        }\n",
    "        self.emotion_labels = ['angry', 'disgusted', 'fearful', 'happy', 'sad', 'surprised', 'neutral']\n",
    "    \n",
    "    def predict_emotion_cnn(self, face_image_path):\n",
    "        \"\"\"Predict emotion using CNN model\"\"\"\n",
    "        if fine_tuned_model is None or not os.path.exists(face_image_path):\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            # Load and preprocess image\n",
    "            img = cv2.imread(face_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                return None\n",
    "                \n",
    "            img_resized = cv2.resize(img, (48, 48))\n",
    "            img_normalized = img_resized.reshape(1, 48, 48, 1) / 255.0\n",
    "            \n",
    "            # Predict\n",
    "            prediction = fine_tuned_model.predict(img_normalized, verbose=0)[0]\n",
    "            return dict(zip(self.emotion_labels, prediction))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è CNN prediction error for {face_image_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def calculate_engagement_hybrid(self, face_api_emotions, cnn_emotions=None):\n",
    "        \"\"\"Calculate engagement using hybrid approach\"\"\"\n",
    "        \n",
    "        # Face API engagement score\n",
    "        face_api_score = sum(\n",
    "            self.emotion_weights.get(emotion, 0) * prob \n",
    "            for emotion, prob in face_api_emotions.items()\n",
    "        )\n",
    "        \n",
    "        # CNN engagement score (if available)\n",
    "        cnn_score = None\n",
    "        if cnn_emotions:\n",
    "            cnn_score = sum(\n",
    "                self.emotion_weights.get(emotion, 0) * prob \n",
    "                for emotion, prob in cnn_emotions.items()\n",
    "            )\n",
    "            \n",
    "            # Weighted combination\n",
    "            hybrid_score = (self.face_api_weight * face_api_score + \n",
    "                          self.cnn_weight * cnn_score)\n",
    "        else:\n",
    "            hybrid_score = face_api_score\n",
    "        \n",
    "        return {\n",
    "            'face_api_score': face_api_score,\n",
    "            'cnn_score': cnn_score,\n",
    "            'hybrid_score': hybrid_score\n",
    "        }\n",
    "    \n",
    "    def classify_engagement_level(self, score):\n",
    "        \"\"\"Classify engagement level based on score\"\"\"\n",
    "        if score > 0.14:\n",
    "            return \"Highly Engaged\"\n",
    "        elif 0.10 <= score <= 0.14:\n",
    "            return \"Engaged\"\n",
    "        else:\n",
    "            return \"Disengaged\"\n",
    "\n",
    "# Initialize hybrid analyzer\n",
    "hybrid_analyzer = HybridEngagementAnalyzer()\n",
    "\n",
    "print(\"\\nüîç RUNNING HYBRID ANALYSIS...\")\n",
    "\n",
    "# Analyze each record\n",
    "hybrid_results = []\n",
    "cnn_predictions_count = 0\n",
    "\n",
    "for idx, row in baseline_data.iterrows():\n",
    "    # Face API emotions\n",
    "    face_api_emotions = {\n",
    "        'neutral': row['neutral'], 'happy': row['happy'], 'sad': row['sad'],\n",
    "        'angry': row['angry'], 'fearful': row['fearful'], \n",
    "        'disgusted': row['disgusted'], 'surprised': row['surprised']\n",
    "    }\n",
    "    \n",
    "    # Find corresponding CNN prediction (if available)\n",
    "    cnn_emotions = None\n",
    "    corresponding_face_path = None\n",
    "    \n",
    "    if face_metadata is not None:\n",
    "        # Try to find matching face data\n",
    "        matching_faces = face_metadata[\n",
    "            (face_metadata['user_id'] == row['user_id'])\n",
    "        ]\n",
    "        \n",
    "        if len(matching_faces) > 0:\n",
    "            # Use first matching face\n",
    "            face_row = matching_faces.iloc[0]\n",
    "            corresponding_face_path = face_row['face_path']\n",
    "            \n",
    "            if os.path.exists(corresponding_face_path):\n",
    "                cnn_emotions = hybrid_analyzer.predict_emotion_cnn(corresponding_face_path)\n",
    "                if cnn_emotions:\n",
    "                    cnn_predictions_count += 1\n",
    "    \n",
    "    # Calculate hybrid engagement\n",
    "    engagement_scores = hybrid_analyzer.calculate_engagement_hybrid(\n",
    "        face_api_emotions, cnn_emotions\n",
    "    )\n",
    "    \n",
    "    # Classify engagement levels\n",
    "    face_api_level = hybrid_analyzer.classify_engagement_level(engagement_scores['face_api_score'])\n",
    "    hybrid_level = hybrid_analyzer.classify_engagement_level(engagement_scores['hybrid_score'])\n",
    "    \n",
    "    hybrid_results.append({\n",
    "        'user_id': row['user_id'],\n",
    "        'page': row.get('page', 'unknown'),\n",
    "        'face_api_score': engagement_scores['face_api_score'],\n",
    "        'cnn_score': engagement_scores['cnn_score'],\n",
    "        'hybrid_score': engagement_scores['hybrid_score'],\n",
    "        'face_api_level': face_api_level,\n",
    "        'hybrid_level': hybrid_level,\n",
    "        'has_cnn_prediction': cnn_emotions is not None,\n",
    "        'face_path': corresponding_face_path\n",
    "    })\n",
    "    \n",
    "    if (idx + 1) % 20 == 0:\n",
    "        print(f\"   Processed {idx + 1}/{len(baseline_data)} records...\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "hybrid_df = pd.DataFrame(hybrid_results)\n",
    "\n",
    "print(f\"\\n‚úÖ Hybrid analysis complete!\")\n",
    "print(f\"üìä Processed {len(hybrid_df)} records\")\n",
    "print(f\"ü§ñ CNN predictions available for {cnn_predictions_count} records ({cnn_predictions_count/len(hybrid_df)*100:.1f}%)\")\n",
    "\n",
    "# Comparison analysis\n",
    "print(f\"\\nüìà COMPARISON ANALYSIS:\")\n",
    "\n",
    "# Engagement level comparison\n",
    "face_api_dist = hybrid_df['face_api_level'].value_counts(normalize=True) * 100\n",
    "hybrid_dist = hybrid_df['hybrid_level'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(f\"\\nüéØ Engagement Level Distribution:\")\n",
    "print(f\"{'Level':<15} {'Face API (%)':<12} {'Hybrid (%)':<12} {'Difference':<12}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for level in ['Disengaged', 'Engaged', 'Highly Engaged']:\n",
    "    face_api_pct = face_api_dist.get(level, 0)\n",
    "    hybrid_pct = hybrid_dist.get(level, 0)\n",
    "    diff = hybrid_pct - face_api_pct\n",
    "    print(f\"{level:<15} {face_api_pct:<12.1f} {hybrid_pct:<12.1f} {diff:+.1f}\")\n",
    "\n",
    "# Correlation analysis (for records with both predictions)\n",
    "records_with_both = hybrid_df[hybrid_df['has_cnn_prediction'] == True]\n",
    "if len(records_with_both) > 1:\n",
    "    correlation = records_with_both['face_api_score'].corr(records_with_both['hybrid_score'])\n",
    "    print(f\"\\nüîó Score Correlation (records with CNN): {correlation:.4f}\")\n",
    "else:\n",
    "    correlation = hybrid_df['face_api_score'].corr(hybrid_df['hybrid_score'])\n",
    "    print(f\"\\nüîó Overall Score Correlation: {correlation:.4f}\")\n",
    "\n",
    "# Visualizations\n",
    "print(f\"\\nüé® Creating comparison visualizations...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Score comparison scatter plot\n",
    "axes[0,0].scatter(hybrid_df['face_api_score'], hybrid_df['hybrid_score'], \n",
    "                  alpha=0.6, color='blue')\n",
    "axes[0,0].plot([-0.3, 0.3], [-0.3, 0.3], 'r--', label='Perfect Agreement')\n",
    "axes[0,0].set_xlabel('Face API Score')\n",
    "axes[0,0].set_ylabel('Hybrid Score')\n",
    "axes[0,0].set_title('Face API vs Hybrid Engagement Scores')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Level distribution comparison\n",
    "levels = ['Disengaged', 'Engaged', 'Highly Engaged']\n",
    "x = np.arange(len(levels))\n",
    "width = 0.35\n",
    "\n",
    "face_api_counts = [face_api_dist.get(level, 0) for level in levels]\n",
    "hybrid_counts = [hybrid_dist.get(level, 0) for level in levels]\n",
    "\n",
    "axes[0,1].bar(x - width/2, face_api_counts, width, label='Face API', alpha=0.8)\n",
    "axes[0,1].bar(x + width/2, hybrid_counts, width, label='Hybrid', alpha=0.8)\n",
    "axes[0,1].set_xlabel('Engagement Level')\n",
    "axes[0,1].set_ylabel('Percentage (%)')\n",
    "axes[0,1].set_title('Engagement Level Distribution Comparison')\n",
    "axes[0,1].set_xticks(x)\n",
    "axes[0,1].set_xticklabels(levels)\n",
    "axes[0,1].legend()\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Per user comparison\n",
    "user_comparison = hybrid_df.groupby('user_id').agg({\n",
    "    'face_api_score': 'mean',\n",
    "    'hybrid_score': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "axes[1,0].scatter(user_comparison['face_api_score'], user_comparison['hybrid_score'])\n",
    "for i, user_id in enumerate(user_comparison['user_id']):\n",
    "    axes[1,0].annotate(f'U{user_id}', \n",
    "                       (user_comparison.iloc[i]['face_api_score'], \n",
    "                        user_comparison.iloc[i]['hybrid_score']))\n",
    "axes[1,0].plot([-0.3, 0.3], [-0.3, 0.3], 'r--', alpha=0.7)\n",
    "axes[1,0].set_xlabel('Face API Average Score')\n",
    "axes[1,0].set_ylabel('Hybrid Average Score')\n",
    "axes[1,0].set_title('Per-User Average Engagement Comparison')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. CNN prediction coverage\n",
    "coverage_data = {\n",
    "    'With CNN': cnn_predictions_count,\n",
    "    'Face API Only': len(hybrid_df) - cnn_predictions_count\n",
    "}\n",
    "\n",
    "axes[1,1].pie(coverage_data.values(), labels=coverage_data.keys(), autopct='%1.1f%%')\n",
    "axes[1,1].set_title('CNN Prediction Coverage')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/hybrid_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Visualizations saved to results/hybrid_comparison.png\")\n",
    "\n",
    "# Save hybrid results\n",
    "hybrid_df.to_csv('results/hybrid_analysis_results.csv', index=False)\n",
    "print(\"üíæ Hybrid results saved to results/hybrid_analysis_results.csv\")\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"üìã FINAL HYBRID ANALYSIS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"üîç METHODOLOGY:\")\n",
    "print(f\"   Face API Weight: {hybrid_analyzer.face_api_weight:.1f}\")\n",
    "print(f\"   CNN Weight: {hybrid_analyzer.cnn_weight:.1f}\")\n",
    "print(f\"   CNN Model: {'Fine-tuned' if 'fine_tuned_model.h5' in str(fine_tuned_model) else 'Pre-trained'}\")\n",
    "\n",
    "print(f\"\\nüìä PERFORMANCE METRICS:\")\n",
    "print(f\"   Total Records: {len(hybrid_df):,}\")\n",
    "print(f\"   Users: {hybrid_df['user_id'].nunique()}\")\n",
    "print(f\"   CNN Coverage: {cnn_predictions_count}/{len(hybrid_df)} ({cnn_predictions_count/len(hybrid_df)*100:.1f}%)\")\n",
    "print(f\"   Score Correlation: {correlation:.4f}\")\n",
    "\n",
    "print(f\"\\nüéØ ENGAGEMENT INSIGHTS:\")\n",
    "print(f\"   Most Common Level (Face API): {face_api_dist.idxmax()} ({face_api_dist.max():.1f}%)\")\n",
    "print(f\"   Most Common Level (Hybrid): {hybrid_dist.idxmax()} ({hybrid_dist.max():.1f}%)\")\n",
    "\n",
    "# Top users\n",
    "user_insights = hybrid_df.groupby('user_id').agg({\n",
    "    'hybrid_score': 'mean',\n",
    "    'hybrid_level': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'Unknown'\n",
    "}).round(4)\n",
    "\n",
    "print(f\"\\nüë• TOP ENGAGED USERS (Hybrid Score):\")\n",
    "top_users = user_insights.sort_values('hybrid_score', ascending=False).head(3)\n",
    "for user_id, data in top_users.iterrows():\n",
    "    print(f\"   User {user_id}: {data['hybrid_score']:.4f} ({data['hybrid_level']})\")\n",
    "\n",
    "print(f\"\\nüéâ HYBRID ANALYSIS COMPLETE!\")\n",
    "print(f\"üìÅ All results saved to 'results/' directory\")\n",
    "\n",
    "# Export final summary\n",
    "final_summary = {\n",
    "    'methodology': f'Hybrid Face API ({hybrid_analyzer.face_api_weight}) + CNN ({hybrid_analyzer.cnn_weight})',\n",
    "    'total_records': len(hybrid_df),\n",
    "    'users': int(hybrid_df['user_id'].nunique()),\n",
    "    'cnn_coverage': f\"{cnn_predictions_count/len(hybrid_df)*100:.1f}%\",\n",
    "    'score_correlation': float(correlation),\n",
    "    'engagement_distribution': {\n",
    "        'face_api': face_api_dist.to_dict(),\n",
    "        'hybrid': hybrid_dist.to_dict()\n",
    "    },\n",
    "    'top_users': top_users.to_dict() if len(top_users) > 0 else {},\n",
    "    'estimated_improvement': 'Hybrid system provides more robust engagement detection'\n",
    "}\n",
    "\n",
    "with open('results/final_hybrid_summary.json', 'w') as f:\n",
    "    json.dump(final_summary, f, indent=2, default=str)\n",
    "\n",
    "print(f\"üíæ Final summary saved to results/final_hybrid_summary.json\")\n",
    "\n",
    "print(f\"\\nüéä CONGRATULATIONS! Hybrid engagement detection system completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "engagement_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
